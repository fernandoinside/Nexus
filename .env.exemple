# Configurações da aplicação
AGENT_NAME=Nexus
APP_PORT=5000
TIMEOUT_AGENT=10

# Configurações do Neo4j
NEO4J_URI="bolt://localhost:7687"
NEO4J_DATABASE="neo4j"
NEO4J_USER="neo4j"
NEO4J_PASSWORD="password"

# Configurações do Redis
REDIS_HOST="localhost"
REDIS_PORT=6379

# Modelo para o Spacy
SPACY_MODEL=pt_core_news_sm

# Modelo para o Embedding
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Chave de acesso da Porcupine - Gerar aqui https://console.picovoice.ai/ (NAO IMPLEMENTADO)
PORCUPINE_ACCESS_KEY=""

# Quando for rodar o seed do banco de dados, setar para true
SEED_DATABASE=false # [true=insere dados no banco com seed, false=não insere]

# Configurações de reconhecimento de voz
INTERACTION_MODE=voz # [voz, texto]

# CHATS IA
# CHATBOT CONFIGURATION
ASK_ENGINE=gpt  # [ollama, gpt, deepseek(nao implementado)]
OLLAMA_MODEL=mistral  # Modelo a ser usado no Ollama (exemplo: mistral, llama2:7b)
# SE FOR USAR (ASK_ENGINE=gpt) UTILIZAR A CHAVE DE ACESSO DA OPENAI
OPENAI_API_KEY=""  # Chave da API da OpenAI para GPT
# SE FOR USAR (ASK_ENGINE=deepseek) UTILIZAR A CHAVE DE ACESSO DA DEEPSEEK
DEEPSEEK=""

# SPEECH CONFIGURATION
SPEECH_ENGINE=coqui  # [google, azure, pyttsx, coqui]
# SE FOR USAR (SPEECH_ENGINE=Azure) UTILIZAR A CHAVE DE ACESSO DA AZURE
AZURE_KEY=  # Chave da API do Azure para síntese de fala
AZURE_REGION=brazilsouth  # Região do Azure, exemplo: 'brazilsouth'
# SE FOR USAR (SPEECH_ENGINE=Google) UTILIZAR A CHAVE DE ACESSO DA GOOGLE
GOOGLE_APPLICATION_CREDENTIALS=caminho/para/google-credentials.json  # Arquivo JSON com credenciais do Google Cloud TTS

# RECOGNITION CONFIGURATION
RECOGNITION_ENGINE=vosk  # Opcional: 'vosk' ou 'speech_recognition'
# VOSK FAZ O RECONHECIMENTO DE VOZ USANDO MODELOS OFFLINE
VOSK_MODEL_PATH=src/models/vosk/vosk-model-small-pt-0.3 # [src/models/vosk/vosk-model-small-pt-0.3, src/models/vosk/vosk-model-pt-fb-v0.1.1-20220516_2113]